import datetime
import logging
import threading
import time
import unittest

from huey import crontab, periodic_command, queue_command, Invoker, BaseConfiguration
from huey.backends.dummy import DummyQueue, DummyDataStore
from huey.exceptions import QueueException
from huey.queue import QueueCommand, PeriodicQueueCommand
from huey.registry import registry
from huey.utils import local_to_utc
from huey.bin.huey_consumer import load_config, Consumer, IterableQueue, MPConsumer, MPIterableQueue

try:
    import multiprocessing
except ImportError:
    multiprocessing = None
#multiprocessing = False

state = test_state = {}

# create a queue, result store and invoker for testing
test_queue = DummyQueue('test-queue')
test_result_store = DummyDataStore('test-queue')
test_task_store = DummyDataStore('test-tasks')

test_invoker = Invoker(test_queue, test_result_store, test_task_store)

# create a dummy config for passing to the consumer
class DummyConfiguration(BaseConfiguration):
    QUEUE = test_queue
    RESULT_STORE = test_result_store
    TASK_STORE = test_result_store
    THREADS = 2

if multiprocessing:
    from huey.backends.redis_backend import *

    mp_test_state = RedisDict("test-state")

    # create a queue, result store and invoker for testing
    mp_test_queue = RedisQueue('test-queue')
    mp_test_result_store = RedisDataStore('test-queue')
    mp_test_task_store = RedisDataStore('test-tasks')

    class MPDummyConfiguration(DummyConfiguration):
        QUEUE = mp_test_queue
        RESULT_STORE = mp_test_result_store
        TASK_STORE = mp_test_task_store

@queue_command(test_invoker)
def modify_state(k, v):
    state[k] = v
    return v

@queue_command(test_invoker)
def blow_up():
    raise Exception('blowed up')

@queue_command(test_invoker, retries=3)
def retry_command(k, always_fail=True):
    if k not in state:
        if not always_fail:
            state[k] = 'fixed'
        raise Exception('fappsk')
    return state[k]

@queue_command(test_invoker, retries=3, retry_delay=10)
def retry_command_slow(k, always_fail=True):
    if k not in state:
        if not always_fail:
            state[k] = 'fixed'
        raise Exception('fappsk')
    return state[k]

@periodic_command(test_invoker, crontab(minute='0'))
def every_hour():
    state['p'] = 'y'

# create a log handler that will track messages generated by the consumer
class TestLogHandler(logging.Handler):
    def __init__(self, *args, **kwargs):
        self.messages = []
        logging.Handler.__init__(self, *args, **kwargs)

    def emit(self, record):
        self.messages.append(record.getMessage())


class SkewConsumerTestCase(unittest.TestCase):
    ConsumerCls = Consumer
    IQCls = IterableQueue
    
    def setUp(self):
        global state
        state = test_state
        state.clear()

        test_invoker.queue = test_queue
        test_invoker.result_store = test_result_store
        test_invoker.task_store = test_task_store

        self.orig_pc = registry._periodic_commands
        registry._periodic_commands = [every_hour.command_class()]

        self.orig_sleep = time.sleep
        time.sleep = lambda x: None
        
        ConsumerCls = self.ConsumerCls
        self.consumer = ConsumerCls(test_invoker, DummyConfiguration)
        self.consumer.invoker.queue.flush()
        self.consumer.invoker.result_store.flush()
        self.consumer.schedule.schedule_dict().clear()
        self.handler = TestLogHandler()
        self.consumer.logger.addHandler(self.handler)

    def tearDown(self):
        self.consumer.shutdown()
        self.consumer.cleanup()
        self.consumer.logger.removeHandler(self.handler)
        registry._periodic_commands = self.orig_pc
        time.sleep = self.orig_sleep

    def test_consumer_loader(self):
        config = load_config('huey.tests.config.Config')
        self.assertTrue(isinstance(config.QUEUE, DummyQueue))
        self.assertEqual(config.QUEUE.name, 'test-queue')

    def spawn(self, func, *args, **kwargs):
        t = threading.Thread(target=func, args=args, kwargs=kwargs)
        t.start()
        return t

    def test_iterable_queue(self):
        store = []
        IQCls = self.IQCls
        q = IQCls()

        def do_queue(queue, result):
            for message in queue:
                result.append(message)

        t = self.spawn(do_queue, q, store)
        q.put(1)
        q.put(2)
        q.put(StopIteration)

        t.join()
        self.assertFalse(t.is_alive())
        self.assertEqual(store, [1, 2])

    def test_message_processing(self):
        self.consumer.start_message_receiver()
        self.consumer.start_worker_pool()

        self.assertFalse('k' in state)

        res = modify_state('k', 'v')
        res.get(blocking=True)

        self.assertTrue('k' in state)
        self.assertEqual(res.get(), 'v')

    def test_worker(self):
        res = modify_state('x', 'y')

        cmd = test_invoker.dequeue()
        self.assertEqual(res.get(), None)

        self.consumer.sync_worker(cmd)

        self.assertTrue('x' in state)
        self.assertEqual(res.get(), 'y')

    def test_worker_exception(self):
        res = blow_up()
        cmd = test_invoker.dequeue()

        self.consumer.sync_worker(cmd)

        self.assertEqual(self.handler.messages, [
            'unhandled exception in worker thread',
        ])

    def test_retries_and_logging(self):
        # this will continually fail
        res = retry_command('blampf')

        cmd = test_invoker.dequeue()
        self.consumer.sync_worker(cmd)
        self.assertEqual(self.handler.messages, [
            'unhandled exception in worker thread',
            're-enqueueing task %s, 2 tries left' % cmd.task_id,
        ])

        cmd = test_invoker.dequeue()
        self.assertEqual(self.consumer.retries_for_command(cmd), 2)
        self.consumer.sync_worker(cmd)
        self.assertEqual(self.handler.messages[-2:], [
            'unhandled exception in worker thread',
            're-enqueueing task %s, 1 tries left' % cmd.task_id,
        ])

        cmd = test_invoker.dequeue()
        self.assertEqual(self.consumer.retries_for_command(cmd), 1)
        self.consumer.sync_worker(cmd)
        self.assertEqual(self.handler.messages[-2:], [
            'unhandled exception in worker thread',
            're-enqueueing task %s, 0 tries left' % cmd.task_id,
        ])

        cmd = test_invoker.dequeue()
        self.assertEqual(self.consumer.retries_for_command(cmd), 0)
        self.consumer.sync_worker(cmd)
        self.assertEqual(len(self.handler.messages), 7)
        self.assertEqual(self.handler.messages[-1:], [
            'unhandled exception in worker thread',
        ])

        self.assertEqual(test_invoker.dequeue(), None)

    def test_retries_with_success(self):
        # this will fail once, then succeed
        res = retry_command('blampf', False)
        self.assertFalse('blampf' in state)

        cmd = test_invoker.dequeue()
        self.consumer.sync_worker(cmd)
        self.assertEqual(self.handler.messages, [
            'unhandled exception in worker thread',
            're-enqueueing task %s, 2 tries left' % cmd.task_id,
        ])

        cmd = test_invoker.dequeue()
        self.assertEqual(self.consumer.retries_for_command(cmd), 2)
        self.consumer.sync_worker(cmd)

        self.assertEqual(state['blampf'], 'fixed')

        self.assertEqual(test_invoker.dequeue(), None)

    def test_pooling(self):
        # simulate acquiring two worker threads
        self.consumer._pool.acquire()
        self.consumer._pool.acquire()

        res = modify_state('x', 'y')

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)

        # work on any messages generated by the processor thread
        st = self.spawn(self.consumer.worker_pool)

        # our result is not available since all workers are blocked
        self.assertEqual(res.get(), None)
        self.assertFalse(self.consumer._pool.acquire(blocking=False))

        # our processor is waiting
        self.assertTrue(pt.is_alive())
        self.assertEqual(self.consumer._queue.qsize(), 0)

        # release a worker
        self.consumer._pool.release()

        # we can get and block now, but will set a timeout of 3 to indicate that
        # something is wrong
        self.assertEqual(res.get(blocking=True, timeout=3), 'y')

        # this is done
        pt.join()

    def test_scheduling(self):
        dt = datetime.datetime(2011, 1, 1, 0, 0)
        dt2 = datetime.datetime(2037, 1, 1, 0, 0)
        r1 = modify_state.schedule(args=('k', 'v'), eta=dt, convert_utc=False)
        r2 = modify_state.schedule(args=('k2', 'v2'), eta=dt2, convert_utc=False)

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)

        # work on any messages generated by the processor thread
        st = self.spawn(self.consumer.worker_pool)

        pt.join()
        self.orig_sleep(0.1)
        self.assertTrue('k' in state)
        self.assertEqual(self.consumer.schedule.schedule_dict(), {})

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)
        pt.join()

        # it got stored in the schedule instead of executing
        self.assertFalse('k2' in state)
        self.assertTrue(r2.command.task_id in self.consumer.schedule.schedule_dict())

        # run through an iteration of the scheduler
        self.consumer.check_schedule(dt)

        # our command was not enqueued
        self.assertEqual(len(self.consumer.invoker.queue), 0)

        # try running the scheduler with the time the command should run
        self.consumer.check_schedule(dt2)

        # it was enqueued
        self.assertEqual(len(self.consumer.invoker.queue), 1)
        self.assertEqual(self.consumer.schedule.schedule_dict(), {})

        # dequeue and inspect -- it won't be executed because the scheduler will
        # see that it is scheduled to run in the future and plop it back into the
        # schedule
        command = self.consumer.invoker.dequeue()
        self.assertEqual(command.task_id, r2.command.task_id)
        self.assertEqual(command.execute_time, dt2)

    def test_retry_scheduling(self):
        # this will continually fail
        res = retry_command_slow('blampf')
        self.assertEqual(len(self.consumer.schedule.schedule_dict()), 0)

        cur_time = datetime.datetime.utcnow()

        cmd = test_invoker.dequeue()
        self.consumer.sync_worker(cmd)
        self.assertEqual(self.handler.messages, [
            'unhandled exception in worker thread',
            're-enqueueing task %s, 2 tries left' % cmd.task_id,
        ])

        self.assertEqual(self.consumer.schedule.schedule_dict(), {
            cmd.task_id: cmd,
        })
        cmd_from_sched = self.consumer.schedule.schedule_dict()[cmd.task_id]
        self.assertEqual(self.consumer.retries_for_command(cmd_from_sched), 2)
        exec_time = cmd.execute_time

        self.assertEqual((exec_time - cur_time).seconds, 10)

    def test_schedule_local_utc(self):
        dt = datetime.datetime(2011, 1, 1, 0, 0)
        dt2 = datetime.datetime(2037, 1, 1, 0, 0)
        r1 = modify_state.schedule(args=('k', 'v'), eta=dt)
        r2 = modify_state.schedule(args=('k2', 'v2'), eta=dt2)

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)

        # work on any messages generated by the processor thread
        st = self.spawn(self.consumer.worker_pool)

        pt.join()
        self.orig_sleep(0.1)
        self.assertTrue('k' in state)
        self.assertEqual(self.consumer.schedule.schedule_dict(), {})

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)
        pt.join()

        # it got stored in the schedule instead of executing
        self.assertFalse('k2' in state)
        self.assertTrue(r2.command.task_id in self.consumer.schedule.schedule_dict())

        # run through an iteration of the scheduler
        self.consumer.check_schedule(dt)

        # our command was not enqueued
        self.assertEqual(len(self.consumer.invoker.queue), 0)

        # try running the scheduler with the time the command should run
        self.consumer.check_schedule(local_to_utc(dt2))

        # it was enqueued
        self.assertEqual(len(self.consumer.invoker.queue), 1)
        self.assertEqual(self.consumer.schedule.schedule_dict(), {})

        # dequeue and inspect -- it won't be executed because the scheduler will
        # see that it is scheduled to run in the future and plop it back into the
        # schedule
        command = self.consumer.invoker.dequeue()
        self.assertEqual(command.task_id, r2.command.task_id)
        self.assertEqual(command.execute_time, local_to_utc(dt2))

    def test_schedule_persistence(self):
        # should not error out as it will be EmptyData
        self.consumer.load_schedule()

        dt = datetime.datetime(2037, 1, 1, 0, 0)
        dt2 = datetime.datetime(2037, 1, 1, 0, 1)
        r = modify_state.schedule(args=('k', 'v'), eta=dt, convert_utc=False)
        r2 = modify_state.schedule(args=('k2', 'v2'), eta=dt2, convert_utc=False)

        # two messages in the queue
        self.assertEqual(len(self.consumer.invoker.queue), 2)

        # pull 'em down
        self.consumer.check_message()
        self.consumer.check_message()

        self.consumer.save_schedule()
        self.consumer.schedule.schedule_dict().clear()

        self.consumer.load_schedule()
        self.assertTrue(r.command.task_id in self.consumer.schedule.schedule_dict())
        self.assertTrue(r2.command.task_id in self.consumer.schedule.schedule_dict())

        cmd1 = self.consumer.schedule.schedule_dict()[r.command.task_id]
        cmd2 = self.consumer.schedule.schedule_dict()[r2.command.task_id]

        self.assertEqual(cmd1.execute_time, dt)
        self.assertEqual(cmd2.execute_time, dt2)

        # check w/conversion
        r3 = modify_state.schedule(args=('k3', 'v3'), eta=dt)
        self.consumer.check_message()

        self.consumer.save_schedule()
        self.consumer.schedule.schedule_dict().clear()

        self.consumer.load_schedule()
        cmd3 = self.consumer.schedule.schedule_dict()[r3.command.task_id]
        self.assertEqual(cmd3.execute_time, local_to_utc(dt))

    def test_revoking_normal(self):
        # enqueue 2 normal commands
        r1 = modify_state('k', 'v')
        r2 = modify_state('k2', 'v2')

        # revoke the first *before it has been checked*
        r1.revoke()
        self.assertTrue(test_invoker.is_revoked(r1.command))
        self.assertFalse(test_invoker.is_revoked(r2.command))

        # dequeue a *single* message (r1)
        pt = self.spawn(self.consumer.check_message)

        # work on any messages generated by the processor thread
        # it should throw out r1 since it is revoked and scheduled
        # to run immediately
        st = self.spawn(self.consumer.worker_pool)

        pt.join()

        # no changes and the task was not added to the schedule
        self.assertFalse('k' in state)
        self.assertEqual(len(self.consumer.schedule.schedule_dict()), 0)

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)
        pt.join()
        self.orig_sleep(0.1)

        self.assertTrue('k2' in state)
        self.assertEqual(len(self.consumer.schedule.schedule_dict()), 0)

    def test_revoking_schedule(self):
        global state
        dt = datetime.datetime(2011, 1, 1)
        dt2 = datetime.datetime(2037, 1, 1)

        r1 = modify_state.schedule(args=('k', 'v'), eta=dt, convert_utc=False)
        r2 = modify_state.schedule(args=('k2', 'v2'), eta=dt, convert_utc=False)
        r3 = modify_state.schedule(args=('k3', 'v3'), eta=dt2, convert_utc=False)
        r4 = modify_state.schedule(args=('k4', 'v4'), eta=dt2, convert_utc=False)

        # revoke r1 and r3
        r1.revoke()
        r3.revoke()
        self.assertTrue(test_invoker.is_revoked(r1.command))
        self.assertFalse(test_invoker.is_revoked(r2.command))
        self.assertTrue(test_invoker.is_revoked(r3.command))
        self.assertFalse(test_invoker.is_revoked(r4.command))

        expected = [
            #state,             schedule
            ({},                {}),
            ({'k2': 'v2'},      {}),
            ({'k2': 'v2'},      {r3.command.task_id: r3.command}),
            ({'k2': 'v2'},      {r3.command.task_id: r3.command, r4.command.task_id: r4.command}),
        ]

        # work on any messages generated by the processor thread
        st = self.spawn(self.consumer.worker_pool)

        for i in range(4):
            estate, esc = expected[i]

            # dequeue a *single* message
            pt = self.spawn(self.consumer.check_message)
            pt.join()

            self.orig_sleep(0.1)
            self.assertEqual(dict(state), estate)
            self.assertEqual(self.consumer.schedule.schedule_dict(), esc)

        # lets pretend its 2037
        self.consumer.check_schedule(dt2 + datetime.timedelta(seconds=1))
        self.assertEqual(len(self.consumer.schedule.schedule_dict()), 0)

        inv = self.consumer.invoker
        command = inv.dequeue()

        sched = self.consumer.schedule
        self.assertTrue(sched.should_run(command, dt2))
        self.assertTrue(sched.can_run(command, dt2))
        inv.execute(command)

        self.assertEqual(state, {'k2': 'v2', 'k4': 'v4'})

    def test_revoking_periodic(self):
        global state
        def assertQ(l):
            self.assertEqual(len(self.consumer.invoker.queue), l)

        # grab a reference to the invoker
        invoker = self.consumer.invoker

        # work on any messages generated by the processor thread
        st = self.spawn(self.consumer.worker_pool)

        # revoke the command once
        every_hour.revoke(revoke_once=True)
        self.assertTrue(every_hour.is_revoked())

        # it will be skipped the first go-round
        dt = datetime.datetime(2011, 1, 1, 0, 0)
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(0)

        # it has not been run
        self.assertEqual(len(state), 0)

        # the next go-round it will be enqueued
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(1)

        # it has still not been run
        self.assertEqual(len(state), 0)

        # dequeue a *single* message
        pt = self.spawn(self.consumer.check_message)
        pt.join()

        # our command was run
        self.orig_sleep(0.1)
        self.assertEqual(dict(state), {'p': 'y'})

        # reset state
        state.clear()

        # revoke the command
        every_hour.revoke()
        self.assertTrue(every_hour.is_revoked())

        # it will no longer be enqueued
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(0)
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(0)

        # restore
        every_hour.restore()
        self.assertFalse(every_hour.is_revoked())

        # it will now be enqueued
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(1)
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(2)

        # reset
        state = {}
        invoker.queue.flush()

        # revoke for an hour
        td = datetime.timedelta(seconds=3600)
        every_hour.revoke(revoke_until=dt + td)
        self.consumer.enqueue_periodic_commands(dt)
        assertQ(0)

        # after an hour it is back
        self.consumer.enqueue_periodic_commands(dt+td)
        assertQ(1)
        self.consumer.enqueue_periodic_commands(dt+(td*2))
        assertQ(2)

        # our data store should reflect the delay
        cmd_obj = every_hour.command_class()
        self.assertEqual(invoker.result_store.count(), 1)
        self.assertTrue(invoker.result_store.peek(cmd_obj.revoke_id))

if multiprocessing:
    class SkewMPConsumerTestCase(SkewConsumerTestCase):
        ConsumerCls = MPConsumer
        IQCls = MPIterableQueue

        def setUp(self):
            global state
            state = mp_test_state
            state.clear()

            test_invoker.queue = mp_test_queue
            test_invoker.result_store = mp_test_result_store
            test_invoker.task_store = mp_test_task_store

            self.orig_pc = registry._periodic_commands
            registry._periodic_commands = [every_hour.command_class()]

            self.orig_sleep = time.sleep
            time.sleep = lambda x: None
            
            ConsumerCls = self.ConsumerCls
            self.consumer = ConsumerCls(test_invoker, MPDummyConfiguration)
            self.handler = TestLogHandler()
            self.consumer.logger.addHandler(self.handler)

        def tearDown(self):
            super(SkewMPConsumerTestCase, self).tearDown()

            self.consumer.invoker.queue.flush()
            self.consumer.invoker.result_store.flush()
            self.consumer.schedule.schedule_dict().clear()

        def test_pooling(self):
            # we trust the underlying pool mechanism of the multiprocessing module in the multiprocessing implementation
            # so it's not really practical to test it the way we do in the threaded version
            return True
